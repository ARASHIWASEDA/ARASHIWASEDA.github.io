<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Chapter_2" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/06/24/Chapter_2/" class="article-date">
  <time class="dt-published" datetime="2024-06-24T08:13:32.000Z" itemprop="datePublished">2024-06-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/24/Chapter_2/">第二章：基本的KD实现</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本章节将正式进入知识蒸馏代码的编写部分，目标是简单复现Hinton老爷子提出的最经典的Knowledge Distillation算法。</p>
<h2 id="导入各种库"><a href="#导入各种库" class="headerlink" title="导入各种库"></a>导入各种库</h2><p>首先导入本篇需要用到的各种库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transform</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> timm.utils.log <span class="keyword">import</span> setup_default_logging</span><br><span class="line"><span class="keyword">from</span> timm.utils.summary <span class="keyword">import</span> get_outdir</span><br><span class="line"><span class="keyword">from</span> timm.utils.checkpoint_saver <span class="keyword">import</span> CheckpointSaver</span><br><span class="line"><span class="keyword">from</span> timm.models <span class="keyword">import</span> create_model, load_checkpoint</span><br><span class="line"><span class="keyword">from</span> distillers <span class="keyword">import</span> get_distiller</span><br></pre></td></tr></table></figure>

<h2 id="初始化logging"><a href="#初始化logging" class="headerlink" title="初始化logging"></a>初始化logging</h2><p>设置logging用于输出日志信息，用法可以查看本仓库第一章。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># logger setting</span></span><br><span class="line">_logger = logging.getLogger(<span class="string">&quot;train&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><p>相较于第一章的参数增加了蒸馏相关配置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># configs setting</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--model&quot;</span>, default=<span class="string">&quot;resnet18&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;model name&#x27;</span>) <span class="comment"># 学生模型</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--learning-rate&quot;</span>, default=<span class="number">0.01</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--epochs&quot;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;epochs to train&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--device&quot;</span>, default=<span class="string">&quot;cuda&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;training device&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch-size&quot;</span>, default=<span class="number">32</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--log-interval&quot;</span>, default=<span class="number">500</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;to print log info every designated iters&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--output&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;output path to save results&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--experiment&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;name of subfolder of outpur dir&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--num-classes&quot;</span>, default=<span class="number">10</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of classes of the dataset&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--pretrained&quot;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--dataset-download&quot;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--dataset&quot;</span>, default=<span class="string">&#x27;cifar10&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;support cifar10 or cifar100 now&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># distillation setting</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--distiller&quot;</span>, default=<span class="string">&#x27;vanilla&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>) <span class="comment"># 蒸馏器名字</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--teacher&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;name of teacher model&#x27;</span>) <span class="comment"># 教师模型</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--teacher-pretrained&quot;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>) <span class="comment"># 这里激活的话会从timm搭导入在imagenet2012与训练的模型，一般用不到，除非要在imagenet2012上训练学生模型</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--teacher-weight&quot;</span>, default=<span class="string">&#x27;./weights/resnet/resnet50_cifar10.pth.tar&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;path of pre-trained teacher weight&#x27;</span>) <span class="comment"># 教师模型路径</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--kd-temperature&quot;</span>, default=<span class="number">4.</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;distillation temperature&#x27;</span>) <span class="comment"># 知识蒸馏温度</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--kd-loss-weight&quot;</span>, default=<span class="number">1.</span>, <span class="built_in">type</span>=<span class="built_in">float</span>) <span class="comment"># 知识蒸馏损失系数</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--gt-loss-weight&quot;</span>, default=<span class="number">1.</span>, <span class="built_in">type</span>=<span class="built_in">float</span>) <span class="comment"># 学生损失函数系数</span></span><br></pre></td></tr></table></figure>

<h2 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h2><p>CIFAR10或者CIAFR100。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.dataset == <span class="string">&#x27;cifar10&#x27;</span>:</span><br><span class="line">    transforms = transform.Compose([</span><br><span class="line">        transform.Resize(<span class="number">224</span>),</span><br><span class="line">        transform.ToTensor(),</span><br><span class="line">        transform.Normalize(mean=(<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), std=(<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>))</span><br><span class="line">    ])</span><br><span class="line">    train_dataset = datasets.CIFAR10(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">True</span>, transform=transforms,</span><br><span class="line">                                     download=args.dataset_download)</span><br><span class="line">    eval_dataset = datasets.CIFAR10(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">False</span>, transform=transforms,</span><br><span class="line">                                    download=args.dataset_download)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    transforms = transform.Compose([</span><br><span class="line">        transform.Resize(<span class="number">224</span>),</span><br><span class="line">        transform.ToTensor(),</span><br><span class="line">        transform.Normalize(mean=((<span class="number">0.5071</span>, <span class="number">0.4867</span>, <span class="number">0.4408</span>)), std=(<span class="number">0.2675</span>, <span class="number">0.2565</span>, <span class="number">0.2761</span>))</span><br><span class="line">    ])</span><br><span class="line">    train_dataset = datasets.CIFAR100(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">True</span>, transform=transforms,</span><br><span class="line">                                      download=args.dataset_download)</span><br><span class="line">    eval_dataset = datasets.CIFAR100(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">False</span>, transform=transforms,</span><br><span class="line">                                     download=args.dataset_download)</span><br><span class="line">    <span class="comment"># create dataloader</span></span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="模型准备"><a href="#模型准备" class="headerlink" title="模型准备"></a>模型准备</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = create_model(args.model, pretrained=args.pretrained, num_classes=args.num_classes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create teacher model</span></span><br><span class="line">teacher = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> args.teacher:</span><br><span class="line">    teacher = create_model(args.teacher, pretrained=args.teacher_pretrained, num_classes=args.num_classes)</span><br><span class="line">    <span class="keyword">if</span> args.teacher_weight:</span><br><span class="line">        load_checkpoint(teacher, args.teacher_weight)</span><br><span class="line">    teacher.requires_grad_(<span class="literal">False</span>)</span><br><span class="line">    teacher.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># create optimizer</span></span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h2 id="蒸馏器准备"><a href="#蒸馏器准备" class="headerlink" title="蒸馏器准备"></a>蒸馏器准备</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create distiller</span></span><br><span class="line">Distiller = get_distiller(args.distiller.lower())</span><br><span class="line">distiller = Distiller(model, teacher, loss_func, args)</span><br><span class="line">distiller.to(device)</span><br><span class="line">optimizer = torch.optim.SGD(distiller.parameters(), lr=args.learning_rate)</span><br></pre></td></tr></table></figure>

<p>这段代码中使用的get_distiller和Distiller来自于自定义的函数和类。</p>
<p>具体的做法是，在train.py下新建文件夹distillers，在distillers文件夹中新建registry.py文件并添加以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">_distiller_dict = defaultdict()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个函数会被用作装饰器，将定义好的蒸馏器类加入到_distiller_dict中，方便后续获取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register_distiller</span>(<span class="params">distiller</span>):</span><br><span class="line">    distiller_name = distiller.__name__.lower()</span><br><span class="line">    _distiller_dict[distiller_name] = distiller</span><br><span class="line">    <span class="keyword">return</span> distiller</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过名字获取对应蒸馏器的类</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_distiller</span>(<span class="params">distiller_name</span>):</span><br><span class="line">    <span class="keyword">return</span> _distiller_dict[distiller_name]</span><br></pre></td></tr></table></figure>

<p>继续在distillers文件夹中添加文件distillation_losses.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是基本kd算法中损失函数的实现，后续在这个文件中还会补充其他的损失函数</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kd_loss</span>(<span class="params">logits_student, logits_teacher, kd_temperature</span>):</span><br><span class="line">    log_pred_student = F.log_softmax(logits_student / kd_temperature, dim=<span class="number">1</span>)</span><br><span class="line">    pred_teacher = F.softmax(logits_teacher / kd_temperature, dim=<span class="number">1</span>)</span><br><span class="line">    loss_kd = F.kl_div(log_pred_student, pred_teacher, reduction=<span class="string">&#x27;batchmean&#x27;</span>)</span><br><span class="line">    loss_kd *= kd_temperature ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> loss_kd</span><br></pre></td></tr></table></figure>

<p>继续在distillers文件夹中添加文件_base.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现一个基础的蒸馏器类，后续所有的蒸馏器都继承于此类</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseDistiller</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, student, teacher, criterion, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(BaseDistiller, self).__init__()</span><br><span class="line">        self.student = student</span><br><span class="line">        self.teacher = teacher</span><br><span class="line">        self.criterion = criterion</span><br><span class="line">        self.args = args</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        这个函数用来统计参数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        student_params = <span class="number">0</span></span><br><span class="line">        teacher_params = <span class="number">0</span></span><br><span class="line">        extra_params = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> n, p <span class="keyword">in</span> self.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> n.startswith(<span class="string">&#x27;student&#x27;</span>):</span><br><span class="line">                student_params += p.numel()</span><br><span class="line">            <span class="keyword">elif</span> n.startswith(<span class="string">&#x27;teacher&#x27;</span>):</span><br><span class="line">                teacher_params += p.numel()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> p.requires_grad:</span><br><span class="line">                    extra_params += p.numel()</span><br><span class="line">        <span class="keyword">return</span> student_params, teacher_params, extra_params</span><br></pre></td></tr></table></figure>

<p>继续在distillers文件夹中添加文件kd.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现KD类</span></span><br><span class="line"><span class="keyword">from</span> .distillation_losses <span class="keyword">import</span> kd_loss</span><br><span class="line"><span class="keyword">from</span> ._base <span class="keyword">import</span> BaseDistiller</span><br><span class="line"><span class="keyword">from</span> .registry <span class="keyword">import</span> register_distiller</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@register_distiller </span><span class="comment"># 用装饰器将这个类记录下来</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KD</span>(<span class="title class_ inherited__">BaseDistiller</span>):</span><br><span class="line">    requires_feature = <span class="literal">False</span> <span class="comment"># 这个参数指示不需要中间层特征</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, student, teacher, criterion, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(KD, self).__init__(student, teacher, criterion, args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image, label</span>):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            self.teacher.<span class="built_in">eval</span>()</span><br><span class="line">            logits_teacher = self.teacher(image)</span><br><span class="line">        logits_student = self.student(image)</span><br><span class="line">        loss_kd = self.args.kd_loss_weight * kd_loss(logits_student, logits_teacher, self.args.kd_temperature)</span><br><span class="line">        loss_gt = self.args.gt_loss_weight * self.criterion(logits_student, label)</span><br><span class="line">        losses_dict = &#123;</span><br><span class="line">            <span class="string">&#x27;loss_kd&#x27;</span>: loss_kd,</span><br><span class="line">            <span class="string">&#x27;loss_gt&#x27;</span>: loss_gt</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> logits_student, losses_dict</span><br></pre></td></tr></table></figure>

<p>继续在distillers文件夹中添加文件vanilla.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了让train.py代码结构统一起来，把非蒸馏的普通训练也写成一个类</span></span><br><span class="line"><span class="keyword">from</span> ._base <span class="keyword">import</span> BaseDistiller</span><br><span class="line"><span class="keyword">from</span> .registry <span class="keyword">import</span> register_distiller</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@register_distiller</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Vanilla</span>(<span class="title class_ inherited__">BaseDistiller</span>):</span><br><span class="line">    requires_feature = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, student, teacher, criterion, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(Vanilla, self).__init__(student, teacher, criterion, args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image, label</span>):</span><br><span class="line">        logits_student = self.student(image)</span><br><span class="line">        loss_gt = self.criterion(logits_student, label)</span><br><span class="line">        losses_dict = &#123;</span><br><span class="line">            <span class="string">&#x27;loss_gt&#x27;</span>: loss_gt</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> logits_student, losses_dict</span><br></pre></td></tr></table></figure>

<p>最后在distillers文件夹中添加文件__init__.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果后面定义类新的类，这里需要再添加条目</span></span><br><span class="line"><span class="keyword">from</span> .vanilla <span class="keyword">import</span> Vanilla</span><br><span class="line"><span class="keyword">from</span> .kd <span class="keyword">import</span> KD</span><br><span class="line"><span class="keyword">from</span> .distillation_losses <span class="keyword">import</span> kd_loss</span><br><span class="line"><span class="keyword">from</span> .registry <span class="keyword">import</span> get_distiller</span><br></pre></td></tr></table></figure>

<h2 id="主函数的剩余部分"><a href="#主函数的剩余部分" class="headerlink" title="主函数的剩余部分"></a>主函数的剩余部分</h2><p>一部分是路径、logger、device等的设置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># process args and some paths</span></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">args_text = yaml.safe_dump(args.__dict__, default_flow_style=<span class="literal">False</span>)</span><br><span class="line">output_path = args.output <span class="keyword">if</span> args.output <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;./output/train&#x27;</span></span><br><span class="line"><span class="keyword">if</span> args.experiment:</span><br><span class="line">    exp_name = args.experiment</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    exp_name = <span class="string">&#x27;-&#x27;</span>.join([</span><br><span class="line">        datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>),</span><br><span class="line">        args.model</span><br><span class="line">    ])</span><br><span class="line">output_dir = get_outdir(output_path, exp_name)</span><br><span class="line">log_path = os.path.join(output_dir, <span class="string">&#x27;train.log&#x27;</span>)</span><br><span class="line">checkpoint_dir = os.path.join(output_dir, <span class="string">&#x27;checkpoints&#x27;</span>)</span><br><span class="line">os.makedirs(checkpoint_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># setup logging</span></span><br><span class="line">setup_default_logging(log_path=log_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># choose device</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>一部分是训练和验证的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train and validation</span></span><br><span class="line">total_train_iters = <span class="built_in">len</span>(train_loader)</span><br><span class="line">total_eval_iters = <span class="built_in">len</span>(eval_loader)</span><br><span class="line">best_metric = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">saver = CheckpointSaver(</span><br><span class="line">    model=model,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    args=args,</span><br><span class="line">    checkpoint_dir=checkpoint_dir,</span><br><span class="line">    recovery_dir=checkpoint_dir,</span><br><span class="line">    decreasing=<span class="literal">False</span>,</span><br><span class="line">    max_history=<span class="number">3</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(output_dir, <span class="string">&#x27;args.yaml&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(args_text)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</span><br><span class="line">        train(epoch=epoch,</span><br><span class="line">              distiller=distiller,</span><br><span class="line">              loader=train_loader,</span><br><span class="line">              optimizer=optimizer,</span><br><span class="line">              args=args,</span><br><span class="line">              device=device,</span><br><span class="line">              total_iters=total_train_iters)</span><br><span class="line"></span><br><span class="line">        best_metric, best_epoch = <span class="built_in">eval</span>(epoch=epoch,</span><br><span class="line">                                       model=model,</span><br><span class="line">                                       loader=eval_loader,</span><br><span class="line">                                       args=args,</span><br><span class="line">                                       device=device,</span><br><span class="line">                                       total_iters=total_eval_iters,</span><br><span class="line">                                       loss_func=loss_func,</span><br><span class="line">                                       saver=saver)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">if</span> best_metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    _logger.info(<span class="string">f&#x27;***** Best metric is <span class="subst">&#123;best_metric:<span class="number">.2</span>f&#125;</span>(<span class="subst">&#123;best_epoch&#125;</span>) *****.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="训练和验证函数"><a href="#训练和验证函数" class="headerlink" title="训练和验证函数"></a>训练和验证函数</h2><p>为了让主函数看起来更加清晰和美观一点，把训练和验证的代码单独写一个新的函数。</p>
<h3 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch, distiller, loader, optimizer, args, device, total_iters</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    distiller.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        image = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        logits_student, losses_dict = distiller(image, labels)</span><br><span class="line">        loss = <span class="built_in">sum</span>(losses_dict.values())</span><br><span class="line">        preds = torch.argmax(logits_student.detach(), dim=<span class="number">1</span>)</span><br><span class="line">        correct += (preds == labels).<span class="built_in">sum</span>()</span><br><span class="line">        total += preds.shape[<span class="number">0</span>]</span><br><span class="line">        acc = <span class="number">100.0</span> * correct / total</span><br><span class="line">        <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span> <span class="keyword">or</span> batch_idx == total_iters - <span class="number">1</span>:</span><br><span class="line">            losses_infos = []</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> losses_dict.items():</span><br><span class="line">                info = <span class="string">f&#x27;<span class="subst">&#123;k.capitalize()&#125;</span> - <span class="subst">&#123;v.item():<span class="number">.4</span>f&#125;</span>&#x27;</span></span><br><span class="line">                losses_infos.append(info)</span><br><span class="line">            losses_info = <span class="string">&#x27;  &#x27;</span>.join(losses_infos)</span><br><span class="line">            _logger.info(</span><br><span class="line">                <span class="string">f&#x27;Train-<span class="subst">&#123;epoch&#125;</span>: [<span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;total_iters&#125;</span>], &#x27;</span></span><br><span class="line">                <span class="string">f&#x27;Loss: <span class="subst">&#123;losses_info&#125;</span>, Acc: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line">            )</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure>

<h3 id="验证函数"><a href="#验证函数" class="headerlink" title="验证函数"></a>验证函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">epoch, model, loader, args, device, total_iters, loss_func, saver</span>):</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (image, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            image = image.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            preds = model(image)</span><br><span class="line">            loss = loss_func(preds, labels)</span><br><span class="line">            pred_labels = torch.argmax(preds, dim=<span class="number">1</span>)</span><br><span class="line">            correct += (pred_labels == labels).<span class="built_in">sum</span>()</span><br><span class="line">            total += pred_labels.shape[<span class="number">0</span>]</span><br><span class="line">            acc = <span class="number">100.0</span> * correct / total</span><br><span class="line">            <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span> <span class="keyword">or</span> batch_idx == total_iters - <span class="number">1</span>:</span><br><span class="line">                _logger.info(</span><br><span class="line">                    <span class="string">f&#x27;\tEval-<span class="subst">&#123;epoch&#125;</span>: [<span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;total_iters&#125;</span>], &#x27;</span></span><br><span class="line">                    <span class="string">f&#x27;Loss: <span class="subst">&#123;loss:<span class="number">.4</span>f&#125;</span>, Acc: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line">                )</span><br><span class="line">        best_metric, best_epoch = saver.save_checkpoint(epoch, metric=acc)</span><br><span class="line">    <span class="keyword">return</span> best_metric, best_epoch</span><br></pre></td></tr></table></figure>

<h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><p>先用vanilla蒸馏器训一个resnet50的模型，在CIFAR10上的准确率是：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">19</span>:<span class="number">49</span>,<span class="number">266</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">4771</span>, Acc: <span class="number">45</span>.<span class="number">31</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">03</span>,<span class="number">699</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">500</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">1073</span>, Acc: <span class="number">50</span>.<span class="number">55</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">45</span>,<span class="number">498</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">781</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">8323</span>, Acc: <span class="number">50</span>.<span class="number">80</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">45</span>,<span class="number">614</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">5672</span>, Acc: <span class="number">43</span>.<span class="number">75</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">56</span>,<span class="number">466</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">156</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">7095</span>, Acc: <span class="number">46</span>.<span class="number">27</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">56</span>,<span class="number">577</span> - timm.utils.checkpoint_saver: [    INFO] - Current checkpoints:</span><br><span class="line"> (&#x27;./output/cifar10/resnet50/vanilla/teacher4/checkpoints/checkpoint-<span class="number">10</span>.pth.tar&#x27;, tensor(<span class="number">46</span>.<span class="number">2700</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet50/vanilla/teacher4/checkpoints/checkpoint-<span class="number">8</span>.pth.tar&#x27;, tensor(<span class="number">43</span>.<span class="number">8100</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet50/vanilla/teacher4/checkpoints/checkpoint-<span class="number">6</span>.pth.tar&#x27;, tensor(<span class="number">43</span>.<span class="number">7100</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">56</span>,<span class="number">578</span> -                train: [    INFO] - ***** Best metric is <span class="number">46</span>.<span class="number">27</span>(<span class="number">10</span>) *****.</span><br></pre></td></tr></table></figure>

<p>然后用上面得到的resnet50当作教师模型，用resnet18当作学生模型，使用kd蒸馏器，在CIAFR10上训练得到的准确率是：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">42</span>:<span class="number">24</span>,<span class="number">718</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">782</span>], Loss: Loss_kd - <span class="number">0</span>.<span class="number">1011</span>  Loss_gt - <span class="number">1</span>.<span class="number">0957</span>, Acc: <span class="number">65</span>.<span class="number">62</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">12</span>,<span class="number">734</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">500</span>/<span class="number">782</span>], Loss: Loss_kd - <span class="number">0</span>.<span class="number">1041</span>  Loss_gt - <span class="number">1</span>.<span class="number">2737</span>, Acc: <span class="number">52</span>.<span class="number">48</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">39</span>,<span class="number">689</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">781</span>/<span class="number">782</span>], Loss: Loss_kd - <span class="number">0</span>.<span class="number">1023</span>  Loss_gt - <span class="number">1</span>.<span class="number">4824</span>, Acc: <span class="number">52</span>.<span class="number">49</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">39</span>,<span class="number">770</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">4355</span>, Acc: <span class="number">43</span>.<span class="number">75</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">50</span>,<span class="number">011</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">156</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">4721</span>, Acc: <span class="number">50</span>.<span class="number">32</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">50</span>,<span class="number">066</span> - timm.utils.checkpoint_saver: [    INFO] - Current checkpoints:</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/kd/student/checkpoints/checkpoint-<span class="number">9</span>.pth.tar&#x27;, tensor(<span class="number">50</span>.<span class="number">8600</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/kd/student/checkpoints/checkpoint-<span class="number">10</span>.pth.tar&#x27;, tensor(<span class="number">50</span>.<span class="number">3200</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/kd/student/checkpoints/checkpoint-<span class="number">8</span>.pth.tar&#x27;, tensor(<span class="number">49</span>.<span class="number">8300</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">43</span>:<span class="number">50</span>,<span class="number">067</span> -                train: [    INFO] - ***** Best metric is <span class="number">50</span>.<span class="number">86</span>(<span class="number">9</span>) *****.</span><br></pre></td></tr></table></figure>

<p>这里由于教师模型训练的epoch太少了，性能反而被学生模型超过了。如果多训练几十个epoch的话不会出现这种情况。</p>
<p>如果不用教师模型，使用vanilla蒸馏器训练resnet18的话，准确率是：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">54</span>:<span class="number">56</span>,<span class="number">784</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">5641</span>, Acc: <span class="number">35</span>.<span class="number">94</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">55</span>:<span class="number">33</span>,<span class="number">660</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">500</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">3965</span>, Acc: <span class="number">50</span>.<span class="number">48</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">55</span>:<span class="number">54</span>,<span class="number">295</span> -                train: [    INFO] - Train-<span class="number">10</span>: [<span class="number">781</span>/<span class="number">782</span>], Loss: Loss_gt - <span class="number">1</span>.<span class="number">6475</span>, Acc: <span class="number">50</span>.<span class="number">70</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">55</span>:<span class="number">54</span>,<span class="number">375</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">0</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">7138</span>, Acc: <span class="number">42</span>.<span class="number">19</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">56</span>:<span class="number">04</span>,<span class="number">871</span> -                train: [    INFO] - 	Eval-<span class="number">10</span>: [<span class="number">156</span>/<span class="number">157</span>], Loss: <span class="number">1</span>.<span class="number">6181</span>, Acc: <span class="number">43</span>.<span class="number">53</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">56</span>:<span class="number">04</span>,<span class="number">924</span> - timm.utils.checkpoint_saver: [    INFO] - Current checkpoints:</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/vanilla/student/checkpoints/checkpoint-<span class="number">10</span>.pth.tar&#x27;, tensor(<span class="number">43</span>.<span class="number">5300</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/vanilla/student/checkpoints/checkpoint-<span class="number">6</span>.pth.tar&#x27;, tensor(<span class="number">43</span>.<span class="number">2800</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/cifar10/resnet18/vanilla/student/checkpoints/checkpoint-<span class="number">9</span>.pth.tar&#x27;, tensor(<span class="number">42</span>.<span class="number">7700</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">15</span>:<span class="number">56</span>:<span class="number">04</span>,<span class="number">925</span> -                train: [    INFO] - ***** Best metric is <span class="number">43</span>.<span class="number">53</span>(<span class="number">10</span>) *****.</span><br></pre></td></tr></table></figure>

<p>可以看到kd确实提高了学生模型的性能。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/06/24/Chapter_2/" data-id="clxspdkz70001osa2fbqzfbiv" data-title="第二章：基本的KD实现" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-contents" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/06/24/contents/" class="article-date">
  <time class="dt-published" datetime="2024-06-24T08:13:32.000Z" itemprop="datePublished">2024-06-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/24/contents/">目录：知识蒸馏算法PyTorch实现教程</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>知识蒸馏是一种模型压缩的方法，指利用性能强大但网络结构复杂的教师模型指导结构更加简单的学生模型训练过程的一种算法。本仓库基于torch和timm库，将简单介绍完成一份基本的知识蒸馏算法的各个步骤，并提供一个简单的知识蒸馏算法框架。</p>
<p>本仓库目前的章节目录如下：</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/06/24/contents/" data-id="clxspdkz90002osa2b0ey3bvl" data-title="目录：知识蒸馏算法PyTorch实现教程" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Chapter_1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/06/24/Chapter_1/" class="article-date">
  <time class="dt-published" datetime="2024-06-24T08:11:43.000Z" itemprop="datePublished">2024-06-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/24/Chapter_1/">第一章：实现基础的图像分类模型训练</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>知识蒸馏的训练过程与普通的模型训练过程的基本逻辑是相似的，因此在介绍知识蒸馏算法的代码实现之前，让我们先复习一下如何利用timm和torch实现一份基本的图像分类模型训练代码。</p>
<p>工欲善其事必先利其器，正式编写训练的核心代码前，先介绍一些在许多代码中都有使用的辅助工具。不用这些也没关系，但是随着代码规模的扩大，使用这些库可以帮助提高编写效率。</p>
<h2 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h2><p>为了在后续的代码中能够方便的管理训练中的诸多参数，推荐使用argparse库。后续如果参数规模增加，可以使用yaml保存部分参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse  <span class="comment"># 首先引入 argparse库</span></span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()  <span class="comment"># 创建一个ArgumentParser类，并添加各种参数</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--learning-rate&quot;</span>, default=<span class="number">0.001</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--epochs&quot;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;epochs to train&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--device&quot;</span>, default=<span class="string">&quot;cuda&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;training device&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--batch-size&quot;</span>, default=<span class="number">32</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--log-interval&quot;</span>, default=<span class="number">500</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;to print log info during every log-interval iterations&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--output&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;output path to save results&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--experiment&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;name of subfolder of outpur dir&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--model&quot;</span>, default=<span class="string">&quot;resnet34&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;model name&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--num-classes&quot;</span>, default=<span class="number">10</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of classes of the dataset&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>在代码的主函数部分，可以很方便的获取到设定的参数。还可以将参数形成yaml文件保存。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml  <span class="comment"># 用来保存args文件</span></span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(args.model)  <span class="comment"># &#x27;resnet34&#x27;</span></span><br><span class="line">args_text = yaml.safe_dump(args.__dict__, default_flow_style=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(output_dir, <span class="string">&#x27;args.yaml&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(args_text)</span><br></pre></td></tr></table></figure>

<h2 id="logging"><a href="#logging" class="headerlink" title="logging"></a>logging</h2><p>为了能够更加方便的观察训练过程中的各项指标，我们可以使用print函数打印出损失、准确率等参数，也可以使用如tqdm等库实现更加清晰优美的可视化效果。本博客推荐使用logging库实现日志输出和保存的功能，并且timm库提供了一个setup_default_logging函数方便我们设置日志的输出和保存效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging  <span class="comment"># 首先依然是引入logging库</span></span><br><span class="line"><span class="keyword">from</span> timm.utils.log <span class="keyword">import</span> setup_default_logging  <span class="comment"># 从timm引入logging的设置函数</span></span><br><span class="line"></span><br><span class="line">_logger = logging.getLogger(<span class="string">&quot;train&quot;</span>)</span><br><span class="line">setup_default_logging(log_path=log_path)  <span class="comment"># 在指定路径生成日志文件</span></span><br><span class="line">_logger.info(<span class="string">&quot;这是一个logging的示例&quot;</span>)  <span class="comment"># 这样就会在console输出文字，用法与print相似</span></span><br></pre></td></tr></table></figure>

<p>点开setup_default_logging函数的源码，看一下是如何实现的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FormatterNoInfo</span>(logging.Formatter):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fmt=<span class="string">&#x27;%(levelname)s: %(message)s&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化一个FormatterNoInfo类，主要目的就是为了格式化日志文件的输出格式</span></span><br><span class="line"><span class="string">        如&#x27;%(levelname)s: %(message)s&#x27;，其中levelname代表logging日志的级别</span></span><br><span class="line"><span class="string">        有ERROR、INFO、DEBUG等，message就是你要输出的信息内容，具体可以自行搜索</span></span><br><span class="line"><span class="string">        _logger.info(&quot;这是一个logging的示例&quot;)的输出为：</span></span><br><span class="line"><span class="string">        &#x27;[INFO]: 这是一个logging的示例&#x27;</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        logging.Formatter.__init__(self, fmt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">format</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">if</span> record.levelno == logging.INFO:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">str</span>(record.getMessage())</span><br><span class="line">        <span class="keyword">return</span> logging.Formatter.<span class="built_in">format</span>(self, record)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_default_logging</span>(<span class="params">default_level=logging.INFO, log_path=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># StreamHandler可以将日志信息输出到console</span></span><br><span class="line">    console_handler = logging.StreamHandler()</span><br><span class="line">    <span class="comment"># 使用上面定义的类，格式化日志输出</span></span><br><span class="line">    console_handler.setFormatter(FormatterNoInfo())</span><br><span class="line">    <span class="comment"># 加入console_handler，不然在console可能没有输出</span></span><br><span class="line">    logging.root.addHandler(console_handler)</span><br><span class="line">    <span class="comment"># 设置输出的级别，低于指定级别的信息不会被记录</span></span><br><span class="line">    <span class="comment"># 如果设置级别为INFO，则DEBUG不会被记录，而ERROR、INFO和更高级别的会记录</span></span><br><span class="line">    logging.root.setLevel(default_level)</span><br><span class="line">    <span class="comment"># 保存日志文件，如果不设置路径就不保存</span></span><br><span class="line">    <span class="keyword">if</span> log_path:</span><br><span class="line">        file_handler = logging.handlers.RotatingFileHandler(log_path, maxBytes=(<span class="number">1024</span> ** <span class="number">2</span> * <span class="number">2</span>), backupCount=<span class="number">3</span>)</span><br><span class="line">        file_formatter = logging.Formatter(<span class="string">&quot;%(asctime)s - %(name)20s: [%(levelname)8s] - %(message)s&quot;</span>)</span><br><span class="line">        file_handler.setFormatter(file_formatter)</span><br><span class="line">        logging.root.addHandler(file_handler)</span><br></pre></td></tr></table></figure>

<p>由于本博客是一个基础的教程，因此基本上只会用到info级别的日志，不用在logging上关注太多，即插即用即可。感兴趣的可以自行搜索学习。</p>
<h2 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h2><p>以图像分类举例，可以通过torchvision库获取数据集。出于方便快捷的目的，这里使用CIFAR10数据集，可以自行换成CIFAR100、MNIST、FashionMNIST等等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transform  <span class="comment"># 读取的数据集需要经过一些变换才可以使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># resnet的输入需要（3，224，224）的图片，先不考虑其他的数据增强</span></span><br><span class="line"><span class="comment"># 后续会介绍另外一个数据增强库</span></span><br><span class="line">transforms = transform.Compose([</span><br><span class="line">    transform.Resize(<span class="number">224</span>),</span><br><span class="line">    transform.ToTensor(),</span><br><span class="line">    transform.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">])</span><br><span class="line"><span class="comment"># root是数据集的存储路径，download设置为true可以自动下载，imagenet是下载不了的</span></span><br><span class="line">train_dataset = datasets.CIFAR10(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">True</span>, transform=transforms, download=<span class="literal">True</span>)</span><br><span class="line">eval_dataset = datasets.CIFAR10(root=<span class="string">&quot;datasets&quot;</span>, train=<span class="literal">False</span>, transform=transforms, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>此时的数据集还不能在训练中使用，但是我们可以通过索引查看任一数据的内容，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_dataset[<span class="number">0</span>])  <span class="comment"># 是一个（3，224，224）的tuple</span></span><br></pre></td></tr></table></figure>

<p>一般使用迭代器的形式遍历数据集中的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader  <span class="comment"># 首先导入库</span></span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=<span class="literal">True</span>)  <span class="comment"># shuffle=True的时候，会打乱顺序</span></span><br><span class="line">eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="模型以及相关内容的准备"><a href="#模型以及相关内容的准备" class="headerlink" title="模型以及相关内容的准备"></a>模型以及相关内容的准备</h2><p>可以使用timm的create_model函数快速的创建需要的模型结构。但是在知识蒸馏中我们可能需要对模型的结构进行修改，这一部分放到后面介绍。先简单的导入一个模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> timm  <span class="comment"># 导入timm库</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载与训练模型，一般是在imagenet上进行的预训练，具体的训练配置可以到timm.models里面查看</span></span><br><span class="line">model = timm.create_model(args.model, pretrained=<span class="literal">True</span>, num_classes=args.num_classes)  <span class="comment"># resnet34</span></span><br><span class="line">model.cuda()  <span class="comment"># 将模型转移到GPU设备上</span></span><br></pre></td></tr></table></figure>

<p>此外，我们至少还需要准备优化器和损失函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer初始化的第一个参数是模型的参数，如果是知识蒸馏代码，这一步会不同</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate)</span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><p>训练好的模型需要保存，在正式开始训练之前，我们先设置好模型的保存路径，模型的保存路径取决于以下的两个参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&quot;--experiment&quot;</span>, default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;name of subfolder of outpur dir&#x27;</span>)  <span class="comment"># 这个参数主要是方便我们给每次实验起个名字方便查找</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--model&quot;</span>, default=<span class="string">&quot;resnet34&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;model name&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>根据提供的参数，我们设置好模型的保存路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.experiment:</span><br><span class="line">    exp_name = args.experiment</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 如果没设置experiment的话就按照时间和模型名字保存</span></span><br><span class="line">    exp_name = <span class="string">&#x27;-&#x27;</span>.join([</span><br><span class="line">        datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>),</span><br><span class="line">        args.model</span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># 使用timm快捷创建路径文件夹，可以看作os.makedirs，产生的路径就是</span></span><br><span class="line"><span class="comment"># os.path.join(output_path,exp_name)</span></span><br><span class="line"><span class="keyword">from</span> timm.utils.summary <span class="keyword">import</span> get_outdir</span><br><span class="line"></span><br><span class="line">output_dir = get_outdir(output_path, exp_name)  <span class="comment"># 返回的是创建好的文件夹的路径</span></span><br><span class="line">checkpoint_dir = os.path.join(output_dir, <span class="string">&#x27;checkpoints&#x27;</span>)  <span class="comment"># 在checkpoints里面保存模型</span></span><br></pre></td></tr></table></figure>

<p>timm创建的模型是基于torch的，所以我们可以使用torch.save的方法保存模型。但是这里我们使用一个更加方便的方法去保存模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.utils.checkpoint_saver <span class="keyword">import</span> CheckpointSaver</span><br><span class="line"></span><br><span class="line">saver = CheckpointSaver(</span><br><span class="line">    model=model,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    args=args,</span><br><span class="line">    checkpoint_dir=checkpoint_dir,</span><br><span class="line">    recovery_dir=checkpoint_dir,</span><br><span class="line">    decreasing=<span class="literal">False</span>,  <span class="comment"># 以指标的升序排列模型</span></span><br><span class="line">    max_history=<span class="number">3</span>  <span class="comment"># 只保存结果最好的3个模型</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>使用上面的方法不仅可以保存模型，还可以自定义许多其他的功能，比我们自己手写模型的保存函数更加方便。当然如果不需要这些功能的话直接使用torch自带的保存功能也，可以参照如下格式简单保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">save_state = &#123;</span><br><span class="line">    <span class="string">&#x27;epoch&#x27;</span>: epoch,</span><br><span class="line">    <span class="string">&#x27;state_dict&#x27;</span>: model.static_dict(),</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line">torch.save(save_state, save_path)</span><br></pre></td></tr></table></figure>

<h2 id="主要训练步骤"><a href="#主要训练步骤" class="headerlink" title="主要训练步骤"></a>主要训练步骤</h2><p>完成上述的各个准备工作之后，可以正式编写模型的训练代码了。</p>
<p>我们用如下的结构编写训练的主要代码结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 这里放训练代码</span></span><br><span class="line"><span class="keyword">except</span> KetBoardInterrupt:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>按照这样的结构编写代码的好处是，运行的时候中断训练过程之后，代码能继续执行剩余的部分，可以留给一些文件的处理和信息保存。</p>
<p>把训练的代码替换try后面的pass，具体如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs + <span class="number">1</span>):  <span class="comment"># 从1开始计算epoch，方便理解</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span>  <span class="comment"># 用来计算acc</span></span><br><span class="line">    model.train()  <span class="comment"># 将模型调整到train的模式，一些特殊算子如dropout会被启用</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (image, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        image = image.cuda()  <span class="comment"># 将数据转移到cuda设备上</span></span><br><span class="line">        labels = labels.cuda()</span><br><span class="line">        preds = model(image)  <span class="comment"># shape：（batchsize，num_classes）</span></span><br><span class="line">        loss = loss_func(preds, labels)</span><br><span class="line">        pred_labels = torch.argmax(preds.detach(), dim=<span class="number">1</span>)  <span class="comment"># shape：batchsize</span></span><br><span class="line">        correct += (pred_labels == labels).<span class="built_in">sum</span>()</span><br><span class="line">        total += pred_labels.shape[<span class="number">0</span>]</span><br><span class="line">        acc = <span class="number">100.0</span> * correct / total</span><br><span class="line">        <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span>:  <span class="comment"># 按照log_interval设置间隔打印信息</span></span><br><span class="line">            _logger.info(</span><br><span class="line">                <span class="string">f&#x27;Train-<span class="subst">&#123;epoch&#125;</span>: [<span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;total_train_iters&#125;</span>], &#x27;</span></span><br><span class="line">                <span class="string">f&#x27;Loss: <span class="subst">&#123;loss.detach():<span class="number">.4</span>f&#125;</span>, Acc: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line">            )</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清理之前保存的梯度信息，不然会一直保存历史梯度</span></span><br><span class="line">        loss.backward()  <span class="comment"># 计算反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 优化器对参数进行迭代更新</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 这一步很关键，不然验证集的梯度信息可能被记录</span></span><br><span class="line">        model.<span class="built_in">eval</span>()  <span class="comment"># 停用dropout等会对验证结果产生负面影响的算子</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (image, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(eval_loader):</span><br><span class="line">            image = image.cuda()</span><br><span class="line">            labels = labels.cuda()</span><br><span class="line">            preds = model(image)</span><br><span class="line">            loss = loss_func(preds, labels)</span><br><span class="line">            pred_labels = torch.argmax(preds, dim=<span class="number">1</span>)</span><br><span class="line">            correct += (pred_labels == labels).<span class="built_in">sum</span>()</span><br><span class="line">            total += pred_labels.shape[<span class="number">0</span>]</span><br><span class="line">            acc = <span class="number">100.0</span> * correct / total</span><br><span class="line">            <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span>:</span><br><span class="line">                _logger.info(</span><br><span class="line">                    <span class="string">f&#x27;\tEval-<span class="subst">&#123;epoch&#125;</span>: [<span class="subst">&#123;batch_idx&#125;</span>/<span class="subst">&#123;total_eval_iters&#125;</span>], &#x27;</span></span><br><span class="line">                    <span class="string">f&#x27;Loss: <span class="subst">&#123;loss:<span class="number">.4</span>f&#125;</span>, Acc: <span class="subst">&#123;acc:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line">                )</span><br><span class="line">        <span class="comment"># 按照指标保存模型，也可以按照loss的最小值保存模型，但在前面需要设置decreasing=True</span></span><br><span class="line">        best_metric, best_epoch = saver.save_checkpoint(epoch, metric=acc)</span><br></pre></td></tr></table></figure>

<p>最后，我们可以加上一行代码输出最好指标的相关信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> best_metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    _logger.info(<span class="string">f&#x27;***** Best metric is <span class="subst">&#123;best_metric:<span class="number">.2</span>f&#125;</span>(<span class="subst">&#123;best_epoch&#125;</span>) *****.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="参考结果"><a href="#参考结果" class="headerlink" title="参考结果"></a>参考结果</h2><p>用resnet18在CIFAR10上跑5个epoch简单看看效果，证明能跑起来就算是完成了。</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">34</span>:<span class="number">11</span>,<span class="number">548</span> -                train: [    INFO] - Train-<span class="number">5</span>: [<span class="number">0</span>/<span class="number">1563</span>], Loss: <span class="number">0</span>.<span class="number">9199</span>, Acc: <span class="number">87</span>.<span class="number">50</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">34</span>:<span class="number">36</span>,<span class="number">611</span> -                train: [    INFO] - Train-<span class="number">5</span>: [<span class="number">500</span>/<span class="number">1563</span>], Loss: <span class="number">0</span>.<span class="number">8576</span>, Acc: <span class="number">75</span>.<span class="number">21</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">01</span>,<span class="number">864</span> -                train: [    INFO] - Train-<span class="number">5</span>: [<span class="number">1000</span>/<span class="number">1563</span>], Loss: <span class="number">0</span>.<span class="number">9366</span>, Acc: <span class="number">75</span>.<span class="number">35</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">27</span>,<span class="number">597</span> -                train: [    INFO] - Train-<span class="number">5</span>: [<span class="number">1500</span>/<span class="number">1563</span>], Loss: <span class="number">0</span>.<span class="number">8731</span>, Acc: <span class="number">75</span>.<span class="number">67</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">30</span>,<span class="number">725</span> -                train: [    INFO] - Train-<span class="number">5</span>: [<span class="number">1562</span>/<span class="number">1563</span>], Loss: <span class="number">0</span>.<span class="number">8844</span>, Acc: <span class="number">75</span>.<span class="number">78</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">30</span>,<span class="number">763</span> -                train: [    INFO] - 	Eval-<span class="number">5</span>: [<span class="number">0</span>/<span class="number">313</span>], Loss: <span class="number">0</span>.<span class="number">9541</span>, Acc: <span class="number">65</span>.<span class="number">62</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">37</span>,<span class="number">324</span> -                train: [    INFO] - 	Eval-<span class="number">5</span>: [<span class="number">312</span>/<span class="number">313</span>], Loss: <span class="number">1</span>.<span class="number">0666</span>, Acc: <span class="number">78</span>.<span class="number">65</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">37</span>,<span class="number">372</span> - timm.utils.checkpoint_saver: [    INFO] - Current checkpoints:</span><br><span class="line"> (&#x27;./output/train\\<span class="number">20240620</span>-<span class="number">152832</span>-resnet18\\checkpoints\\checkpoint-<span class="number">5</span>.pth.tar&#x27;, tensor(<span class="number">78</span>.<span class="number">6500</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/train\\<span class="number">20240620</span>-<span class="number">152832</span>-resnet18\\checkpoints\\checkpoint-<span class="number">4</span>.pth.tar&#x27;, tensor(<span class="number">74</span>.<span class="number">9300</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"> (&#x27;./output/train\\<span class="number">20240620</span>-<span class="number">152832</span>-resnet18\\checkpoints\\checkpoint-<span class="number">2</span>.pth.tar&#x27;, tensor(<span class="number">67</span>.<span class="number">0100</span>, device=&#x27;cuda:<span class="number">0</span>&#x27;))</span><br><span class="line"></span><br><span class="line"><span class="number">2024</span>-<span class="number">06</span>-<span class="number">20</span> <span class="number">15</span>:<span class="number">35</span>:<span class="number">37</span>,<span class="number">372</span> -                train: [    INFO] - ***** Best metric is <span class="number">78</span>.<span class="number">65</span>(<span class="number">5</span>) *****.</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/06/24/Chapter_1/" data-id="clxspdkz50000osa28pvmfpze" data-title="第一章：实现基础的图像分类模型训练" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/06/24/Chapter_2/">第二章：基本的KD实现</a>
          </li>
        
          <li>
            <a href="/2024/06/24/contents/">目录：知识蒸馏算法PyTorch实现教程</a>
          </li>
        
          <li>
            <a href="/2024/06/24/Chapter_1/">第一章：实现基础的图像分类模型训练</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>