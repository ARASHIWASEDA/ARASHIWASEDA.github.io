# ARASHIWASEDA.github.io

## 知识蒸馏算法代码编写教程

知识蒸馏是一种模型压缩的方法，指利用性能强大但网络结构复杂的教师模型指导结构更加简单的学生模型训练过程的一种算法。本仓库基于torch和timm库，将简单介绍完成一份基本的知识蒸馏算法的各个步骤，并提供一个简单的知识蒸馏算法框架。

本仓库目前的章节目录如下：

[第一章：实现基础的图像分类模型训练 - Knowledge distillation implementation (arashiwaseda.github.io)](https://arashiwaseda.github.io/2023/06/24/Chapter_1/)

[第二章：基本的KD实现 - Knowledge distillation implementation (arashiwaseda.github.io)](https://arashiwaseda.github.io/2023/07/02/Chapter_2/)

[第三章：解耦合知识蒸馏算法 - Knowledge distillation implementation (arashiwaseda.github.io)](https://arashiwaseda.github.io/2023/07/18/Chapter_3/)